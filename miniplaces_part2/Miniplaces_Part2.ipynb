{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.819 / 6.869 Miniplaces Part 2\n",
    "\n",
    "Welcome to the Miniplaces Challenge, Part 2!\n",
    "\n",
    "The goal of this challenge is to make a scene classifier that classifies a 128x128 image into one of several categories. \n",
    "The Miniplaces dataset is a more managable subset of the larger \"Places\" dataset, with images from 100 categories.\n",
    "\n",
    "During the challenge, you will try and get the best top-5 accuracy on the test set, whose labels are hidden. You will submit your inferences for each of the test-set images to a web server for grading.\n",
    "\n",
    "\n",
    "# Pretrained Networks are NOT allowed!\n",
    "\n",
    "**Throughout this challenge, you MAY NOT use pretrained weights, or other datasets, to train your network.**\n",
    "\n",
    "While in the real world, you often want to start a task by finetuning a network trained on ImageNet, getting improvements from there is very computationally expensive. There are many techniques you can use to improve your performance, without just using massive datasets and computation. To make it a fairer competition, that isn't computation-limited, you MAY NOT use pretrained weights (you can, of course, save and load weights as you do the challenge). Using pretrained networks will get you disqualified.\n",
    "\n",
    "# Logistics\n",
    "Read carefully!\n",
    "\n",
    "The Miniplaces Challenge is released on Thu 11/7. \\\n",
    "**Submissions are due by Friday 11/14 at 11:59PM** (We extended the deadline by 1 day to account for the delay in releasing the PSet)\n",
    "\n",
    "**This Challenge will take a lot of time, because you're training networks. Please start early!**\n",
    "\n",
    "You may work in teams of up to 2. Such teams will need to submit individual reports, but may use the same code / results.\n",
    "\n",
    "You will need to train neural networks from scratch, which will need GPUs. We encourage you to use AWS servers or Google Colab, if you do not have access to a GPU locally. We provide $100 of AWS credits that you can use on the Miniplaces Challenge, and you can use the remainder for your final project. We don't expect Miniplaces will use all of this credit though. If you need more credits (particularly for final projects), post a Private question on Piazza addressed to all Staff.\n",
    "\n",
    "You should submit a zip file with a PDF report and your code on stellar whose filename is prefixed by your kerberos ex: `yourkerberos.zip`. We only care that your kerberos is clearly visible - if it helps you organize, you may add more to the filename, seperated by underscore (`yourkerberos_miniplaces2.zip`). Make sure to submit the correct zip file! Please do NOT submit the dataset in your submission! (It's huge!)\n",
    "\n",
    "Additionally, during this challenge, you will use your model to label a test set. We will be hosting a web server that evaluates your labelling. Your model should guess 5 categories for each test image. If any one of these is correct, we will say your model has classified the image correctly. This metric is called the \"Top-5\" Error. \n",
    "\n",
    "In order to get full credit for this assignment, you must make a submission with a Top-5 Error of less than 30%.\n",
    "The top 20 teams in the class will recieve 10% extra credit on this assignment, and the top 5 teams will receive 20% extra credit.\n",
    "\n",
    "You may submit this assignment up to 1 week late, with partial credit that linearly decreases to 1/2 credit, as indicated by our late policy on the course website. However, late submissions will NOT count when finding the top-20 and top-5 teams for extra credit.\n",
    "\n",
    "# Writeup\n",
    "\n",
    "See the PDF for details on what you need to include in your report\n",
    "\n",
    "# Submission Server\n",
    "The file `miniplaces_grader.py` contains the client code necessary to submit test set evaluations, form a team, and get AWS credits. Please use the `-h` flag of that script for usage. Run that locally! \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_name = \"FILL IN YOUR NAME HERE\"\n",
    "my_teammate = \"\" # Fill in if you have a teammate, leave blank otherwise\n",
    "my_team_name = \"YOUR TEAM NAME HERE\" # Your team name on the submission server\n",
    "\n",
    "print(\"I'm %s. I worked with %s. I'm on team %s\" % (my_name, my_teammate, my_team_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Downloading the dataset\n",
    "\n",
    "You can download the dataset from <http://6.869.csail.mit.edu/fa19/miniplaces_part2/data.zip>\n",
    "\n",
    "The entire dataset is also available unzipped in Google Drive from \\\n",
    "<https://drive.google.com/drive/folders/1-IvzghOb7mesv3d-AvYpbtY9HCwQfisQ?usp=sharing> \\\n",
    "If you're using Google Colab, you should use this folder and \"Add to My Drive\", since then it will count against the Teaching Staff's Google Drive quota instead of your own.\n",
    "\n",
    "Unzip this to some directory. Our data folder follows the format of the `ImageFolder` class <https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "expected_name = \"Miniplaces_Part2.ipynb\"\n",
    "\n",
    "# Colab specific setup\n",
    "try:\n",
    "  from google.colab import drive\n",
    "  \n",
    "except Exception:\n",
    "  # Local setup\n",
    "  rootpath = \".\"\n",
    "\n",
    "else:\n",
    "  drive.mount('/content/gdrive')\n",
    "  print(\"This will take a while, depending on how many folders you have in your google drive (your drive has to be mounted into the machine)\")\n",
    "  rootpath = None\n",
    "  for (parent_dir, subfolders, subfiles) in os.walk('/content/gdrive'):\n",
    "    if expected_name in subfiles:\n",
    "      print(\"Found this file! Setting root path to: %s\" % parent_dir)\n",
    "      rootpath = parent_dir\n",
    "      break\n",
    "  if rootpath is None:\n",
    "    raise Exception(\"Could not find this notebook (%s). Did you change the name? If so, change expected_name variable\" % expected_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Root of data. Change this to match your directory structure. \n",
    "# Your submissions should NOT include the data.\n",
    "# You might want to mount your google drive, if you're using google colab. \n",
    "# If you ran the cell above, your google drive will be located at '/content/gdrive/My Drive'\n",
    "# datadir should contain train/ val/ and test/\n",
    "\n",
    "\n",
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Training a Model\n",
    "\n",
    "Now, we'll train a model. This code was adapted from <https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html>\n",
    "\n",
    "You are free to delete this code entirely and start from scratch, or modify it in whatever way you choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# You might not have tqdm, which gives you nice progress bars\n",
    "!pip install tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "else:\n",
    "    print(\"WARNING: Could not find GPU! Using CPU only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize an Empty Model\n",
    "\n",
    "First, we need to initialize an empty model, that will input an image, and output a classification. Each model is a little different, so we'll make a helper function that takes in an architecture name, and outputs a model. This is only meant as a guideline, and you can try using different models! `torchvision.models` has other common architectures, and variations on these (like ResNet-50 and ResNet-101), so you may want to try those out.\n",
    "\n",
    "We also add a `resume_from` argument to specify model weights to load, In case you save a model and want to use it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, resume_from = None):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    # The model (nn.Module) to return\n",
    "    model_ft = None\n",
    "    # The input image is expected to be (input_size, input_size)\n",
    "    input_size = 0\n",
    "    \n",
    "    # You may NOT use pretrained models!! \n",
    "    use_pretrained = False\n",
    "    \n",
    "    # By default, all parameters will be trained (useful when you're starting from scratch)\n",
    "    # Within this function you can set .requires_grad = False for various parameters, if you\n",
    "    # don't want to learn them\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Invalid model name!\")\n",
    "    \n",
    "    if resume_from is not None:\n",
    "        print(\"Loading weights from %s\" % resume_from)\n",
    "        model_ft.load_state_dict(torch.load(resume_from))\n",
    "    \n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "With the input size from the model, we can now load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(input_size, batch_size, shuffle = True):\n",
    "    # How to transform the image when you are loading them.\n",
    "    # you'll likely want to mess with the transforms on the training set.\n",
    "    \n",
    "    # For now, we resize/crop the image to the correct input size for our network,\n",
    "    # then convert it to a [C,H,W] tensor, then normalize it to values with a given mean/stdev. These normalization constants\n",
    "    # are derived from aggregating lots of data and happen to produce better results.\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "    # Create training and validation datasets\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in data_transforms.keys()}\n",
    "    # Create training and validation dataloaders\n",
    "    # Never shuffle the test set\n",
    "    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False if x != 'train' else shuffle, num_workers=4) for x in data_transforms.keys()}\n",
    "    return dataloaders_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Next, let's make a helper function that trains the given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, save_dir = None, save_all_epochs=False, num_epochs=25):\n",
    "    '''\n",
    "    model: The NN to train\n",
    "    dataloaders: A dictionary containing at least the keys \n",
    "                 'train','val' that maps to Pytorch data loaders for the dataset\n",
    "    criterion: The Loss function\n",
    "    optimizer: The algorithm to update weights \n",
    "               (Variations on gradient descent)\n",
    "    num_epochs: How many epochs to train for\n",
    "    save_dir: Where to save the best model weights that are found, \n",
    "              as they are found. Will save to save_dir/weights_best.pt\n",
    "              Using None will not write anything to disk\n",
    "    save_all_epochs: Whether to save weights for ALL epochs, not just the best\n",
    "                     validation error epoch. Will save to save_dir/weights_e{#}.pt\n",
    "    '''\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            # TQDM has nice progress bars\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # torch.max outputs the maximum value, and its index\n",
    "                    # Since the input is batched, we take the max along axis 1\n",
    "                    # (the meaningful outputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backprop + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer & Loss\n",
    "We need a loss function, and an optimization function to use to try to reduce that loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(model):\n",
    "    # Get all the parameters\n",
    "    params_to_update = model.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "    # Use SGD\n",
    "    optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "    return optimizer\n",
    "\n",
    "def get_loss():\n",
    "    # Create an instance of the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "Here, we set up some of the various parameters that we can change to run the code. You can add change the values given here, or add new ones! This is just a template.\n",
    "\n",
    "Our data is conveniently set up to follow the expected format of the  `ImageFolder <https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder>`__\n",
    "dataset class, rather than writing our own custom dataset.\n",
    "\n",
    "The ``model_name`` input is the name of the model you wish to use. We've provided starter code that initializes these models using provided models in TorchVision (a PyTorch library)\n",
    "\n",
    "The code as is supports the following values: [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "\n",
    "The other inputs are as follows: ``num_classes`` is the number of\n",
    "classes in the dataset, 100 here, ``batch_size`` is the batch size used for\n",
    "training and may be adjusted according to the capability of your\n",
    "machine, ``num_epochs`` is the number of training epochs (passes through the dataset) we want to run.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "# You can add your own, or modify these however you wish!\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "# Miniplaces has 100\n",
    "num_classes = 100\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "# You should use a power of 2.\n",
    "batch_size = 8\n",
    "\n",
    "# Shuffle the input data?\n",
    "shuffle_datasets = True\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 10\n",
    "\n",
    "### IO\n",
    "# Path to a model file to use to start weights at\n",
    "resume_from = None\n",
    "\n",
    "# Directory to save weights to\n",
    "save_dir = \"weights\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save weights for all epochs, not just the best one\n",
    "save_all_epochs = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tying it all together - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the model for this run\n",
    "model, input_size = initialize_model(model_name = model_name, num_classes = num_classes, resume_from = resume_from)\n",
    "dataloaders = get_dataloaders(input_size, batch_size, shuffle_datasets)\n",
    "criterion = get_loss()\n",
    "\n",
    "# Move the model to the gpu if needed\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = make_optimizer(model)\n",
    "\n",
    "# Train the model!\n",
    "trained_model, validation_history = train_model(model=model, dataloaders=dataloaders, criterion=criterion, optimizer=optimizer,\n",
    "           save_dir=save_dir, save_all_epochs=save_all_epochs, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Inference\n",
    "\n",
    "Now that we've trained a model, we would like to evaluate its performance (on the validation data), and use it for inference (on the test data). We're going to perform top-5 inference - that is, our model will get to output 5 guesses for a given image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, is_labelled = False, generate_labels = True, k = 5):\n",
    "    # If is_labelled, we want to compute loss, top-1 accuracy and top-5 accuracy\n",
    "    # If generate_labels, we want to output the actual labels\n",
    "    # Set the model to evaluate mode\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    running_top1_correct = 0\n",
    "    running_top5_correct = 0\n",
    "    predicted_labels = []\n",
    "    \n",
    "\n",
    "    # Iterate over data.\n",
    "    # TQDM has nice progress bars\n",
    "    for inputs, labels in tqdm(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        tiled_labels = torch.stack([labels.data for i in range(k)], dim=1) \n",
    "        # Makes this to calculate \"top 5 prediction is correct\"\n",
    "        # [[label1 label1 label1 label1 label1], [label2 label2 label2 label label2]]\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            # Get model outputs and calculate loss\n",
    "            outputs = model(inputs)\n",
    "            if is_labelled:\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # torch.topk outputs the maximum values, and their indices\n",
    "            # Since the input is batched, we take the max along axis 1\n",
    "            # (the meaningful outputs)\n",
    "            _, preds = torch.topk(outputs, k=5, dim=1)\n",
    "            if generate_labels:\n",
    "                # We want to store these results\n",
    "                nparr = preds.cpu().detach().numpy()\n",
    "                predicted_labels.extend([list(nparr[i]) for i in range(len(nparr))])\n",
    "\n",
    "        if is_labelled:\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            # Check only the first prediction\n",
    "            running_top1_correct += torch.sum(preds[:, 0] == labels.data)\n",
    "            # Check all 5 predictions\n",
    "            running_top5_correct += torch.sum(preds == tiled_labels)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # Only compute loss & accuracy if we have the labels\n",
    "    if is_labelled:\n",
    "        epoch_loss = float(running_loss / len(dataloader.dataset))\n",
    "        epoch_top1_acc = float(running_top1_correct.double() / len(dataloader.dataset))\n",
    "        epoch_top5_acc = float(running_top5_correct.double() / len(dataloader.dataset))\n",
    "    else:\n",
    "        epoch_loss = None\n",
    "        epoch_top1_acc = None\n",
    "        epoch_top5_acc = None\n",
    "    \n",
    "    # Return everything\n",
    "    return epoch_loss, epoch_top1_acc, epoch_top5_acc, predicted_labels\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data on the validation set\n",
    "# Setting this to false will be a little bit faster\n",
    "generate_validation_labels = True\n",
    "val_loss, val_top1, val_top5, val_labels = evaluate(model, dataloaders['val'], criterion, is_labelled = True, generate_labels = generate_validation_labels, k = 5)\n",
    "\n",
    "# Get predictions for the test set\n",
    "_, _, _, test_labels = evaluate(model, dataloaders['test'], criterion, is_labelled = False, generate_labels = True, k = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Prep & Human-Readable Inference\n",
    "\n",
    "Now that we have predicted labels for our data, let's convert the predictions into a nice JSON that we can submit to the web server!\n",
    "\n",
    "Note that this will only work if you are NOT shuffling your dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' These convert your dataset labels into nice human readable names '''\n",
    "\n",
    "import json\n",
    "\n",
    "def label_number_to_name(lbl_ix):\n",
    "    return dataloaders['val'].dataset.classes[lbl_ix]\n",
    "\n",
    "def dataset_labels_to_names(dataset_labels, dataset_name):\n",
    "    # dataset_name is one of 'train','test','val'\n",
    "    dataset_root = os.path.join(data_dir, dataset_name)\n",
    "    found_files = []\n",
    "    for parentdir, subdirs, subfns in os.walk(dataset_root):\n",
    "        parentdir_nice = os.path.relpath(parentdir, dataset_root)\n",
    "        found_files.extend([os.path.join(parentdir_nice, fn) for fn in subfns if fn.endswith('.jpg')])\n",
    "    # Sort alphabetically, this is the order that our dataset will be in\n",
    "    found_files.sort()\n",
    "    # Now we have two parallel arrays, one with names, and the other with predictions\n",
    "    assert len(found_files) == len(dataset_labels), \"Found more files than we have labels\"\n",
    "    preds = {os.path.basename(found_files[i]):list(map(label_number_to_name, dataset_labels[i])) for i in range(len(found_files))}\n",
    "    return preds\n",
    "    \n",
    "\n",
    "test_labels_js = dataset_labels_to_names(test_labels,\"test\")\n",
    "\n",
    "output_test_labels = \"test_set_predictions\"\n",
    "output_salt_number = 0\n",
    "\n",
    "output_label_dir = \".\"\n",
    "\n",
    "while os.path.exists(os.path.join(output_label_dir, '%s%d.json' % (output_test_labels, output_salt_number))):\n",
    "    output_salt_number += 1\n",
    "    # Find a filename that doesn't exist\n",
    "    \n",
    "\n",
    "with open(os.path.join(output_label_dir, '%s%d.json' % (output_test_labels, output_salt_number)), \"w\") as f:\n",
    "    json.dump(test_labels_js, f, sort_keys=True, indent=4)\n",
    "    \n",
    "print(\"Wrote predictions to:\\n%s\" % os.path.abspath(os.path.join(output_label_dir, '%s%d.json' % (output_test_labels, output_salt_number))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Server Submission\n",
    "\n",
    "Now that you have a prediction JSON file, you should submit it via webserver using the `miniplaces_grader.py` script!\n",
    "\n",
    "Use `-h` for up-to-date help on the script. You can use it to create your miniplaces team, request AWS credits, view the leaderboards, and view the test set scores for your submission.\n",
    "\n",
    "If your score is \"Pending\" - don't worry! We only allow 1 submission per 2 hours, and will release results each time this timer resets. This is to prevent you from overfitting to the test set - you can overfit to the training set easily (since you train on it). You can overfit to the validation set, since you choose your hyperparameters based on that. You can ALSO overfit to the test set, by choosing your model based on your test set performance. So, to prevent you from using the test set too many times (at which point it would become part of your training), we restrict how often you can test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
